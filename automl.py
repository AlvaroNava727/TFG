import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from autogluon.tabular import TabularPredictor
from sklearn.metrics import mean_squared_error, r2_score


# ðŸ“‚ Cargar el archivo CSV (ya contiene 'FechaTrasplante')
file_path = "CLAD_solf.csv"
df = pd.read_csv(file_path, sep=';', encoding='latin1', low_memory=False)

df = df.dropna(subset=['FEV1por_Actualpor'])

# ðŸ”¹ Convertir 'Fecha' y 'FechaTrasplante' a formato datetime
df['Fecha'] = pd.to_datetime(df['Fecha'], format='%d/%m/%Y', errors='coerce')
df['FechaTrasplante'] = pd.to_datetime(df['FechaTrasplante'], format='%d/%m/%Y', errors='coerce')

# ðŸ”¹ Calcular "DiasDesdeTransplante"
df['DiasDesdeTransplante'] = np.where(
    df['Fecha'] < df['FechaTrasplante'], 0,  # Si la fecha es anterior al trasplante, poner 0
    (df['Fecha'] - df['FechaTrasplante']).dt.days  # Si es posterior, calcular dÃ­as transcurridos
)

# ðŸ”¹ Crear la columna 'Transplante' (1 si la fecha es posterior o igual al trasplante, 0 si es anterior)
df['Transplante'] = np.where(df['Fecha'] >= df['FechaTrasplante'], 1, 0)

# ðŸ”¹ Eliminar columnas no utilizadas
df = df.drop(columns=['IdCaso','Evolucion', 'talla', 'FEV1por_Actualml', 'FechaTrasplante', 'Ausencia de rechazo agudo'], errors='ignore')
df['Altura'] = df['Altura'].round(2)
df = df.dropna(thresh=15)

# ðŸ”¹ Eliminar columnas con mÃ¡s del 97% de valores NaN


# ðŸ”¹ Separar tensiÃ³n arterial en dos columnas
df[['Tension_Sistolica', 'Tension_Diastolica']] = df['TensionArterial'].str.split('/', expand=True).astype(float)
df = df.drop(columns=['TensionArterial'])

# ðŸ”¹ Convertir variables categÃ³ricas a numÃ©ricas
temp_mapping = {
    'Hipotermia': 0,
    'Normotermia': 1,
    'FebrÃ­cula': 2,
    'Hipertermia': 3,
    
}
df['GradoTemperatura'] = df['GradoTemperatura'].map(temp_mapping)

sexo_mapping = {
    'M': 1,  # Mujer â†’ 1
    'V': 0   # VarÃ³n â†’ 0
}
df['Sexo'] = df['Sexo'].map(sexo_mapping)

test6min_mapping = {
    'SÃ­': 1,  # SÃ­ â†’ 1
    'No': 0   # No â†’ 0
}
df['Test6min'] = df['Test6min'].map(test6min_mapping)

df["Tratamiento con ADO"] = np.where(df["DiabetesMellitus"] == "Tratamiento con ADO", 1, 
                                     np.where(df["DiabetesMellitus"].isna(), np.nan, 0))

df["Tratamiento con Insulina"] = np.where(df["DiabetesMellitus"] == "Tratamiento con Insulina", 1, 
                                          np.where(df["DiabetesMellitus"].isna(), np.nan, 0))

# ðŸ”¹ Eliminar la columna original "DiabetesMellitus"
df.drop(columns=["DiabetesMellitus"], inplace=True)

hta_mapping = {
    'No': 0,
    'SÃ­': 1
}
df['HTA'] = df['HTA'].map(hta_mapping)

dislip_mapping = {
    'No': 0,
    'SÃ­': 1
}
df['Dislipemia'] = df['Dislipemia'].map(dislip_mapping)

gs_mapping = {'M': 1, 'AB': 2, 'B': 3}
df['GrupoSanguineo'] = df['GrupoSanguineo'].map(gs_mapping)

# ðŸ”¹ Lista de los valores Ãºnicos en la columna "Tipo"
medicamentos = ["Tacrolimus", "Sirolimus", "Everolimus", "Ciclosporina 0", "Ciclosporina 2", "MMF", "Digoxina", "Levetiracetam", "Voriconazol"]

# ðŸ”¹ Crear columnas binarias (1 si "Tipo" contiene ese medicamento, 0 si no)
for medicamento in medicamentos:
    df[medicamento] = (df["Tipo"] == medicamento).astype(int)

# ðŸ”¹ Eliminar la columna original "Tipo" para evitar duplicaciÃ³n
df.drop(columns=["Tipo"], inplace=True)

descripcion_mapping = {
    "Secreciones purulentas": 5,
    "Estenosis vÃ­a aÃ©rea": 4,
    "Dehiscencia": 3,
    "Otros": 2,
    "Normal": 1
}
df["DescripcionBroncoscopia"] = df["DescripcionBroncoscopia"].map(descripcion_mapping)





# ðŸ”¹ Eliminar columnas con mÃ¡s del 97% de valores NaN
umbral = 0.97
df = df.loc[:, df.isnull().mean() < umbral]

df.columns = [col.replace("[", "").replace("]", "").replace("<", "_") for col in df.columns]

print(len(df))

# ðŸ”¹ Imprimir nÃºmero de pacientes Ãºnicos en la columna "Registro"
num_pacientes = df["Registro"].nunique()
print(f'ðŸ”¹ NÃºmero total de pacientes: {num_pacientes}')

# ðŸ”¹ Separar el 10% final de cada paciente como test (solo si hay al menos 10 registros)
# Se conserva el Ã­ndice original en test_data para que la separaciÃ³n sea correcta.
test_data = df.groupby("Registro").apply(
    lambda x: x.iloc[-max(1, int(len(x) * 0.1)):]).reset_index(level=0, drop=True)
train_data = df[~df.index.isin(test_data.index)]

# ðŸ”¹ Eliminar filas donde FEV1por_Actualpor sea NaN
train_data = train_data.dropna(subset=['FEV1por_Actualpor'])
test_data = test_data.dropna(subset=['FEV1por_Actualpor'])
print("NÃºmero de muestras en test_data:", len(test_data))
print("NÃºmero de muestras en train_data:", len(train_data))

# ðŸ”¹ Preparar los datos para AutoGluon
# Se eliminan columnas que no se desean usar como caracterÃ­sticas (por ejemplo, 'Registro' y 'Fecha')
drop_cols = ['Registro', 'Fecha']
train_data_ag = train_data.drop(columns=drop_cols, errors='ignore')
test_data_ag = test_data.drop(columns=drop_cols, errors='ignore')

# ðŸ”¹ Entrenar el modelo con AutoGluon
# AutoGluon utiliza el DataFrame completo (con la variable objetivo incluida) y se encarga de la selecciÃ³n de modelos.
predictor = TabularPredictor(label='FEV1por_Actualpor', problem_type='regression', path='AutogluonModels').fit(train_data_ag, hyperparameters={
            'GBM': {}, 
            'CAT': {}, 
            'XT': {},           
            'XGB': {},
            'RF': {} 
        }, presets='best_quality_v082')

# ðŸ”¹ Realizar predicciones en el conjunto de test
# Se debe eliminar la columna objetivo para la predicciÃ³n.
X_test_ag = test_data_ag.drop(columns=['FEV1por_Actualpor'], errors='ignore')
y_test = test_data_ag['FEV1por_Actualpor']

# ðŸ“‚ Guardar el conjunto de test sin la variable objetivo
test_csv_path = r"Dataset_Test.csv"  # Ajusta la ruta si es necesario
X_test_ag.to_csv(test_csv_path, index=False, sep=';', encoding="utf-8")

print(f"âœ… Archivo de test guardado en: {test_csv_path}")


y_pred = predictor.predict(X_test_ag)

# ðŸ”¹ Calcular RMSE y RÂ²
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f'âœ… RMSE: {rmse:.4f}')
print(f'âœ… R^2: {r2:.4f}')

# ðŸ”¹ Opcional: Mostrar el leaderboard con los modelos entrenados
print(predictor.leaderboard(test_data_ag, silent=True))

X_all = pd.concat([train_data, test_data], axis=0)  # Unimos todos los datos
X_all = X_all.drop(columns=['Registro', 'Fecha'], errors='ignore')  # Eliminar columnas no numÃ©ricas

feature_importance = predictor.feature_importance(X_all, subsample_size=None)

# ðŸ“Œ Ordenar por importancia descendente
feature_importance = feature_importance.sort_values(by="importance", ascending=False)

# ðŸ“Œ Mostrar las primeras 15 caracterÃ­sticas mÃ¡s importantes
print(feature_importance.head(15))

# ðŸ“Š Visualizar la importancia de las caracterÃ­sticas
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.barh(feature_importance.index[:15], feature_importance["importance"][:15], color="royalblue")
plt.xlabel("Importancia")
plt.ylabel("CaracterÃ­sticas")
plt.title("Importancia de las CaracterÃ­sticas segÃºn AutoGluon")
plt.gca().invert_yaxis()  # Para que la caracterÃ­stica mÃ¡s importante aparezca arriba
plt.grid(axis="x", linestyle="--", alpha=0.7)
plt.show()